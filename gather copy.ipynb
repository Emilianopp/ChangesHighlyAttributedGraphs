{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import tweepy \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>author_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-05 18:03:58+00:00</td>\n",
       "      <td>RezayatHadis</td>\n",
       "      <td>1551256587129573378</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Iran, pianist, مهسا_امینی]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>#Iran\\n#pianist \\n#مهسا_امینی https://t.co/rc2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-05 17:43:04+00:00</td>\n",
       "      <td>journalistsay</td>\n",
       "      <td>1385266495</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tehran, Iran, IranRevolution]</td>\n",
       "      <td>Sadeghiyeh Metro Station | ایستگاه مترو صادقیه</td>\n",
       "      <td>Dec 5—#Tehran, #Iran \\nThe protesters in the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-05 11:27:49+00:00</td>\n",
       "      <td>salar__bagheri</td>\n",
       "      <td>1565399154121129986</td>\n",
       "      <td>[]</td>\n",
       "      <td>[اعتصابات_سراسری, ایران, Iran]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>رییس محترم قوه قضاییه توصیه ای رو به والدین کر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-04 23:25:24+00:00</td>\n",
       "      <td>alishahbaziart</td>\n",
       "      <td>1236046969140850688</td>\n",
       "      <td>[]</td>\n",
       "      <td>[مهسا_امینی, زن_زندگی_آزادی, ايران_آزاد, woman...</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>ظلم نمى ماند . .  .\\n.\\n#مهسا_امینی #زن_زندگی_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-04 21:24:48+00:00</td>\n",
       "      <td>marzprad</td>\n",
       "      <td>1580317621412511744</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Iran]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Wanna know one of many truths related to the I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-04 14:23:51+00:00</td>\n",
       "      <td>IrnaEnglish</td>\n",
       "      <td>813279088865644544</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Iran]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>#Iran FM spox slams crackdown on European prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-12-04 14:19:46+00:00</td>\n",
       "      <td>IrnaEnglish</td>\n",
       "      <td>813279088865644544</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Iran]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Cmdr. says #Iran's Bushehr has progressed in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-04 13:48:58+00:00</td>\n",
       "      <td>sheykhian_h</td>\n",
       "      <td>1469389022271262729</td>\n",
       "      <td>[2359926157]</td>\n",
       "      <td>[Iran, ChinaUprising]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Blocking the streets in China is the same meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-04 08:39:12+00:00</td>\n",
       "      <td>babakhaghi1982</td>\n",
       "      <td>1410490384484950016</td>\n",
       "      <td>[]</td>\n",
       "      <td>[photography, streetphotography, outdoors, bab...</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Rainy Afternoon \\nhttps://t.co/YIkuOebAZ2\\n202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-12-04 08:18:40+00:00</td>\n",
       "      <td>AliGodFather92</td>\n",
       "      <td>830685854544908288</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Europeans, protests, Iran, media]</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Isn't it a bit strange for #Europeans that the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        username            author_id  \\\n",
       "0 2022-12-05 18:03:58+00:00    RezayatHadis  1551256587129573378   \n",
       "1 2022-12-05 17:43:04+00:00   journalistsay           1385266495   \n",
       "2 2022-12-05 11:27:49+00:00  salar__bagheri  1565399154121129986   \n",
       "3 2022-12-04 23:25:24+00:00  alishahbaziart  1236046969140850688   \n",
       "4 2022-12-04 21:24:48+00:00        marzprad  1580317621412511744   \n",
       "5 2022-12-04 14:23:51+00:00     IrnaEnglish   813279088865644544   \n",
       "6 2022-12-04 14:19:46+00:00     IrnaEnglish   813279088865644544   \n",
       "7 2022-12-04 13:48:58+00:00     sheykhian_h  1469389022271262729   \n",
       "8 2022-12-04 08:39:12+00:00  babakhaghi1982  1410490384484950016   \n",
       "9 2022-12-04 08:18:40+00:00  AliGodFather92   830685854544908288   \n",
       "\n",
       "       mentions                                           hashtags  \\\n",
       "0            []                        [Iran, pianist, مهسا_امینی]   \n",
       "1            []                     [Tehran, Iran, IranRevolution]   \n",
       "2            []                     [اعتصابات_سراسری, ایران, Iran]   \n",
       "3            []  [مهسا_امینی, زن_زندگی_آزادی, ايران_آزاد, woman...   \n",
       "4            []                                             [Iran]   \n",
       "5            []                                             [Iran]   \n",
       "6            []                                             [Iran]   \n",
       "7  [2359926157]                              [Iran, ChinaUprising]   \n",
       "8            []  [photography, streetphotography, outdoors, bab...   \n",
       "9            []                 [Europeans, protests, Iran, media]   \n",
       "\n",
       "                                         location  \\\n",
       "0                     République islamique d'Iran   \n",
       "1  Sadeghiyeh Metro Station | ایستگاه مترو صادقیه   \n",
       "2                     République islamique d'Iran   \n",
       "3                     République islamique d'Iran   \n",
       "4                     République islamique d'Iran   \n",
       "5                     République islamique d'Iran   \n",
       "6                     République islamique d'Iran   \n",
       "7                     République islamique d'Iran   \n",
       "8                     République islamique d'Iran   \n",
       "9                     République islamique d'Iran   \n",
       "\n",
       "                                                text  \n",
       "0  #Iran\\n#pianist \\n#مهسا_امینی https://t.co/rc2...  \n",
       "1  Dec 5—#Tehran, #Iran \\nThe protesters in the c...  \n",
       "2  رییس محترم قوه قضاییه توصیه ای رو به والدین کر...  \n",
       "3  ظلم نمى ماند . .  .\\n.\\n#مهسا_امینی #زن_زندگی_...  \n",
       "4  Wanna know one of many truths related to the I...  \n",
       "5  #Iran FM spox slams crackdown on European prot...  \n",
       "6  Cmdr. says #Iran's Bushehr has progressed in l...  \n",
       "7  Blocking the streets in China is the same meth...  \n",
       "8  Rainy Afternoon \\nhttps://t.co/YIkuOebAZ2\\n202...  \n",
       "9  Isn't it a bit strange for #Europeans that the...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tweepy \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class api():\n",
    "    def __init__(self,bearer) -> None:\n",
    "        self.client = tweepy.Client(bearer_token=bearer)\n",
    "\n",
    "    def scrape(self,query,num_tweets):\n",
    " \n",
    "        # Creating DataFrame using pandas\n",
    "        db = pd.DataFrame(columns=['date',\n",
    "                                   'username',\n",
    "                                   'author_id',\n",
    "                                   'mentions',\n",
    "                                   'hashtags',\n",
    "                                   'location',\n",
    "                                   'text'])\n",
    "\n",
    "        tweets  = self.client.search_all_tweets(query=query, \n",
    "                                                tweet_fields = ['author_id','created_at','text','source','lang','geo'],\n",
    "                                                user_fields = ['name','username','location','verified'],\n",
    "                                                expansions = ['geo.place_id', 'author_id'],\n",
    "                                                place_fields = ['country','country_code'] ,\n",
    "                                                max_results=num_tweets)\n",
    "\n",
    "        list_tweets = [tweet for tweet in tweets[0]]\n",
    "        i = 1\n",
    "        places = {p[\"id\"]: p for p in tweets.includes['places']}\n",
    "        for tweet in list_tweets:\n",
    "\n",
    "                username = self.client.get_user(id = tweet.author_id).data.username\n",
    "                raw_names = re.findall(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)\",tweet.text)\n",
    "                raw_names = [x.lower() for x in raw_names]\n",
    "                if raw_names:\n",
    "                        raw_names = list(dict.fromkeys(raw_names))\n",
    "\n",
    "                        mentions = [x.id for x in self.client.get_users(usernames = raw_names).data] \n",
    "                else: \n",
    "                        mentions = []\n",
    "                if places[tweet.geo['place_id']]:\n",
    "                        location = places[tweet.geo['place_id']].full_name\n",
    "                date = tweet.created_at\n",
    "                hashtags = re.findall(r\"#(\\w+)\", tweet.text)\n",
    "\n",
    "                ith_tweet = [date,\n",
    "                             username,\n",
    "                             tweet.author_id,\n",
    "                             mentions,\n",
    "                             hashtags,\n",
    "                             location ,\n",
    "                             tweet.text]\n",
    "\n",
    "                db.loc[len(db)] = ith_tweet\n",
    "                i = i+1\n",
    "        filename = 'scraped_tweets.csv'\n",
    "\n",
    "        db.to_csv(filename,index = False)\n",
    "        return db\n",
    "\n",
    "load_dotenv()\n",
    "from datetime import datetime\n",
    "use = api(os.getenv('bearer'))\n",
    "use.scrape('#Iran place_country:IR',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment():\n",
    "    def __init__(self,english_model,english_tokenizer,farsi_model,farsi_tokenizer) -> None:\n",
    "        self.english_model = english_model\n",
    "        self.english_tokenizer = english_tokenizer\n",
    "        self.farsi_model = farsi_model\n",
    "        self.farsi_tokenizer = farsi_tokenizer\n",
    "    def check_language(self,s): \n",
    "        s2 = re.sub(r'([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', ' ',s).replace('\\n',' ')\n",
    "        s2 = re.sub(' +', ' ', s2)\n",
    "        prop = len(s2)/len(s)\n",
    "        if prop > .1: \n",
    "            input_ids = self.farsi_tokenizer.encode(s2, return_tensors=\"pt\")\n",
    "            res = self.farsi_model.generate(input_ids,max_length=300)\n",
    "            output = self.farsi_tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "            print(res)\n",
    "            return output[0]\n",
    "        else: \n",
    "            text = self.preprocess_english(s)\n",
    "            encoded_input = self.english_tokenizer(text, return_tensors='pt')\n",
    "            output = self.english_model(**encoded_input)\n",
    "            scores = output[0][0].detach().numpy()\n",
    "            scores = softmax(scores)\n",
    "            ranking = np.argsort(scores)\n",
    "            ranking = ranking[::-1]\n",
    "            out = labels[np.argmax(ranking)]\n",
    "            return out\n",
    "\n",
    "    def analyze(self,df:pd.DataFrame,target_col='text',output_col = 'sentiment'):\n",
    "        df[output_col] = df.text.apply(lambda x: self.check_language(x))\n",
    "        return df \n",
    "    def preprocess_english(self,text):\n",
    "        new_text = []\n",
    "    \n",
    "    \n",
    "        for t in text.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            new_text.append(t)\n",
    "        return \" \".join(new_text)           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilianopenaloza/mambaforge/envs/weldon/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   375, 34225, 17385,   345,     1]])\n",
      "tensor([[    0,   375, 34225, 17385,   345,     1]])\n",
      "tensor([[    0,   259, 32588,     1]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>author_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-05 18:03:58+00:00</td>\n",
       "      <td>RezayatHadis</td>\n",
       "      <td>1551256587129573378</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Iran', 'pianist', 'مهسا_امینی']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>#Iran\\n#pianist \\n#مهسا_امینی https://t.co/rc2...</td>\n",
       "      <td>no sentiment expressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-05 17:43:04+00:00</td>\n",
       "      <td>journalistsay</td>\n",
       "      <td>1385266495</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Tehran', 'Iran', 'IranRevolution']</td>\n",
       "      <td>Sadeghiyeh Metro Station | ایستگاه مترو صادقیه</td>\n",
       "      <td>Dec 5—#Tehran, #Iran \\nThe protesters in the c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-05 11:27:49+00:00</td>\n",
       "      <td>salar__bagheri</td>\n",
       "      <td>1565399154121129986</td>\n",
       "      <td>[]</td>\n",
       "      <td>['اعتصابات_سراسری', 'ایران', 'Iran']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>رییس محترم قوه قضاییه توصیه ای رو به والدین کر...</td>\n",
       "      <td>no sentiment expressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-04 23:25:24+00:00</td>\n",
       "      <td>alishahbaziart</td>\n",
       "      <td>1236046969140850688</td>\n",
       "      <td>[]</td>\n",
       "      <td>['مهسا_امینی', 'زن_زندگی_آزادی', 'ايران_آزاد',...</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>ظلم نمى ماند . .  .\\n.\\n#مهسا_امینی #زن_زندگی_...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-04 21:24:48+00:00</td>\n",
       "      <td>marzprad</td>\n",
       "      <td>1580317621412511744</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Iran']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Wanna know one of many truths related to the I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-04 14:23:51+00:00</td>\n",
       "      <td>IrnaEnglish</td>\n",
       "      <td>813279088865644544</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Iran']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>#Iran FM spox slams crackdown on European prot...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-12-04 14:19:46+00:00</td>\n",
       "      <td>IrnaEnglish</td>\n",
       "      <td>813279088865644544</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Iran']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Cmdr. says #Iran's Bushehr has progressed in l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-04 13:48:58+00:00</td>\n",
       "      <td>sheykhian_h</td>\n",
       "      <td>1469389022271262729</td>\n",
       "      <td>[2359926157]</td>\n",
       "      <td>['Iran', 'ChinaUprising']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Blocking the streets in China is the same meth...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-04 08:39:12+00:00</td>\n",
       "      <td>babakhaghi1982</td>\n",
       "      <td>1410490384484950016</td>\n",
       "      <td>[]</td>\n",
       "      <td>['photography', 'streetphotography', 'outdoors...</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Rainy Afternoon \\nhttps://t.co/YIkuOebAZ2\\n202...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-12-04 08:18:40+00:00</td>\n",
       "      <td>AliGodFather92</td>\n",
       "      <td>830685854544908288</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Europeans', 'protests', 'Iran', 'media']</td>\n",
       "      <td>République islamique d'Iran</td>\n",
       "      <td>Isn't it a bit strange for #Europeans that the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date        username            author_id  \\\n",
       "0  2022-12-05 18:03:58+00:00    RezayatHadis  1551256587129573378   \n",
       "1  2022-12-05 17:43:04+00:00   journalistsay           1385266495   \n",
       "2  2022-12-05 11:27:49+00:00  salar__bagheri  1565399154121129986   \n",
       "3  2022-12-04 23:25:24+00:00  alishahbaziart  1236046969140850688   \n",
       "4  2022-12-04 21:24:48+00:00        marzprad  1580317621412511744   \n",
       "5  2022-12-04 14:23:51+00:00     IrnaEnglish   813279088865644544   \n",
       "6  2022-12-04 14:19:46+00:00     IrnaEnglish   813279088865644544   \n",
       "7  2022-12-04 13:48:58+00:00     sheykhian_h  1469389022271262729   \n",
       "8  2022-12-04 08:39:12+00:00  babakhaghi1982  1410490384484950016   \n",
       "9  2022-12-04 08:18:40+00:00  AliGodFather92   830685854544908288   \n",
       "\n",
       "       mentions                                           hashtags  \\\n",
       "0            []                  ['Iran', 'pianist', 'مهسا_امینی']   \n",
       "1            []               ['Tehran', 'Iran', 'IranRevolution']   \n",
       "2            []               ['اعتصابات_سراسری', 'ایران', 'Iran']   \n",
       "3            []  ['مهسا_امینی', 'زن_زندگی_آزادی', 'ايران_آزاد',...   \n",
       "4            []                                           ['Iran']   \n",
       "5            []                                           ['Iran']   \n",
       "6            []                                           ['Iran']   \n",
       "7  [2359926157]                          ['Iran', 'ChinaUprising']   \n",
       "8            []  ['photography', 'streetphotography', 'outdoors...   \n",
       "9            []         ['Europeans', 'protests', 'Iran', 'media']   \n",
       "\n",
       "                                         location  \\\n",
       "0                     République islamique d'Iran   \n",
       "1  Sadeghiyeh Metro Station | ایستگاه مترو صادقیه   \n",
       "2                     République islamique d'Iran   \n",
       "3                     République islamique d'Iran   \n",
       "4                     République islamique d'Iran   \n",
       "5                     République islamique d'Iran   \n",
       "6                     République islamique d'Iran   \n",
       "7                     République islamique d'Iran   \n",
       "8                     République islamique d'Iran   \n",
       "9                     République islamique d'Iran   \n",
       "\n",
       "                                                text               sentiment  \n",
       "0  #Iran\\n#pianist \\n#مهسا_امینی https://t.co/rc2...  no sentiment expressed  \n",
       "1  Dec 5—#Tehran, #Iran \\nThe protesters in the c...                positive  \n",
       "2  رییس محترم قوه قضاییه توصیه ای رو به والدین کر...  no sentiment expressed  \n",
       "3  ظلم نمى ماند . .  .\\n.\\n#مهسا_امینی #زن_زندگی_...                negative  \n",
       "4  Wanna know one of many truths related to the I...                positive  \n",
       "5  #Iran FM spox slams crackdown on European prot...                positive  \n",
       "6  Cmdr. says #Iran's Bushehr has progressed in l...                negative  \n",
       "7  Blocking the streets in China is the same meth...                positive  \n",
       "8  Rainy Afternoon \\nhttps://t.co/YIkuOebAZ2\\n202...                 neutral  \n",
       "9  Isn't it a bit strange for #Europeans that the...                positive  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "tokenizer_english  = AutoTokenizer.from_pretrained(MODEL)\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "model_english = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "tokenizer_farsi = AutoTokenizer.from_pretrained(\"persiannlp/mt5-base-parsinlu-sentiment-analysis\")\n",
    "\n",
    "model_farsi = AutoModelForSeq2SeqLM.from_pretrained(\"persiannlp/mt5-base-parsinlu-sentiment-analysis\")\n",
    "\n",
    "sent = Sentiment(model_english,tokenizer_english,model_farsi,tokenizer_farsi)\n",
    "sent.analyze(pd.read_csv('scraped_tweets.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ظلم نمى ماند مهسا امینی زن زندگی آزادی ايران آزاد '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = re.sub(r'([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', ' ',s).replace('\\n',' ')\n",
    "s2 = re.sub(' +', ' ', s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model('ظلم نمى ماند مهسا امینی زن زندگی آزادی ايران آزاد')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we have the following graphs: \n",
    "\n",
    "Number of tweets per hashtag per day \n",
    "line chart \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3773b107c7544bce7f8520392a63589f5d68d536329a0c59b34310458f9d15fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('weldon': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
